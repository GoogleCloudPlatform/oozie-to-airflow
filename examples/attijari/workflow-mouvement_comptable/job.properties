#*************************************************
#  job.properties
#*************************************************

nameNode=hdfs://${master}:8020
queueName=launcher
oozie.libpath=${nameNode}/user/oozie/share/lib
oozie.use.system.libpath=true
oozie.wf.rerun.failnodes=true
oozie.action.sharelib.for.spark=spark3,hbase
workflowName=mouvement_comptable
workflowAppUri=${nameNode}/awb_${env}/awb_ingestion/workflows/workflow-${workflowName}
oozie.coord.application.path=${workflowAppUri}/coordinator/coord.xml
dataPath=${nameNode}/awb_${env}/awb_ingestion/data/${workflowName}
workflowsDataUri=${nameNode}/awb_${env}/awb_ingestion/data

dateAndNumberOfLinesScriptName=date_and_number_of_lines.sh
dateAndNumberOfLinesScriptPath=${workflowAppUri}/scripts/${dateAndNumberOfLinesScriptName}
insertTraceHDFSScriptName=insert_trace_hdfs.sh
insertTraceHDFSScriptPath=${workflowAppUri}/scripts/${insertTraceHDFSScriptName}

#  WF PARAMS
sworkflowAppUri=${nameNode}/awb_${env}/awb_ingestion/workflows/workflow-spark_check
sworkflow=sub-workflow.xml

sep=';'
num_header=0
num_footer=0
header_contains_date=-1
date_position=0
